# Introducing the Podcast

[Script](https://docs.google.com/document/d/1RotYphjVBema8ARXOgbFmluG7KfUE3_R714TC-x1Ja0/edit)

Survey fill out [link](http://bit.ly/2MozP5x). Results [link](https://docs.google.com/forms/d/1eeQFO8usXal16Mx-o5G1kypsUrGCNMVhZmhcZQ9CM4I/edit#responses) (possibly only Ed can see)

# Questions for Ed and Tarek

Hello, and welcome to Hut 23. This series of podcasts is coming to you from the Alan Turing Institute, the UK’s national institute for data science and artificial intelligence.

Over the course of the next few months, we’ll be having a chat about some of the hard questions facing data scientists around the world.

We’ll also be looking at how researchers at the Turing are hoping to use AI to tackle some of today’s tough challenges, from revolutionising disease diagnosis to taking better care of our national infrastructure using ‘smart’ digital models.

Today, we’ll be chatting about what artificial intelligence actually means to us at the Turing, and why people keep talking about "AI research".

But first, who are we? I’m Ben Walden, your host, and I’m here with Ed Chalstrey, a member of our Research Software Engineering group here at the Turing, with a background in developing software to aid drug development; and Tarek Allam a Turing doctoral student working on the Large Synoptic Survey Telescope.

We’re here in London, in the beautiful British Library. Ed, Tarek, how’re you both feeling this chilly Friday morning? 

In my experience, scientists love to talk, so to keep things brief I’ve got my timer here, and I’m going to step in whenever your answers start to get out of hand.

0. What are the applications of AI we're going to be talking about on this podcast?

2. I read an article recently in which a professor of machine learning suggested it would be more appropriate to call a lot of today's AI technology "computers and statistics". What's he getting at?

3. Do you think that when the general public hear "Artificial Intelligence", they're thinking of  Terminator and the Matrix, or are people a bit more clued up as to whats going on?

1. Whats the deal with deal with artificial intelligence? Why can't people agree on how to define AI, and what counts?

4. Nowadays, a lot of algorithms used for the kind of data science and statistics problems you guys work on are being grouped under the umbrella term "Machine Learning" or "ML". Is this  helpful, or is it another definition problem we'd need an entire podcast episode on?

5. I've heard the term "narrow AI" before. How does narrow AI differ from "general AI"? Where are we now?

6. The Alan Turing Institute, where we all work, is the UK national institute for data science and AI; What's the definition of AI that makes most sense in *our* context as researchers? I think listeners should bear mind your answer when we talk about specific research projects in future episodes.

7. Bit of an open question - Whats your favourite example of AI research being done at the Turing right now?

8. We did a poll of the research fellows at the Turing about when, if ever, we might see the creation of AGI. We found that most fellows don't expect to see a true artificial general intelligence first being built for at least a few hundered years, with several claiming it'll take more than a thousand. We also got quite a few angry replies about how stupid our poll was! Why so long for an AGI to be built?

9. Whats an example of a skill that a human can do that an AI can't yet, and why could it take robots a while to catch up?

10. What is the Turing test? - (*Ed comment: possibly beyond scope of ep 1*)

11. So with it being so long before AI can pass as a humans, can we stop worrying about robots taking our jobs, or is there still good reason to worry? - (*Ed comment: possibly beyond scope of ep 1*)

13. People are claiming that we need our AI to be explainable, autidable and transparent, if they're going to making increasingly impactful decisions - what does this mean, and why is it so difficult?

14. As AI's used more and more across society, who's responsible for the decisions they're making? Is it the people who write the algorithms, or the people who train them?

15. Why are people scared about AI going wrong, or turning on us?

16. What do you hope is the next step, or milestone, for the use of AI in data science? How is the Turing working towards that goal?




